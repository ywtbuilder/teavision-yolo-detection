# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license

# YOLO26-BiFormer: Tea Bud Detection model based on YOLO26 with Bi-Level Routing Attention
# Based on paper: "BiFormer: Vision Transformer with Bi-Level Routing Attention" (CVPR 2023)
#
# Improvements over standard YOLO26:
# 1. Bi-Level Routing Attention (BRA) - query-adaptive sparse attention with O((HW)^{4/3}) complexity
# 2. C2fBRA module - C2f blocks with integrated BRA for efficient global context modeling
# 3. P2 feature fusion - incorporates low-level features for small object detection
#
# BiFormer Key Insight:
#   - Level 1: Region-to-region routing - computes region affinity, keeps top-k regions
#   - Level 2: Token-to-token attention - fine-grained attention within routed regions
#   - Achieves query-adaptive sparsity without distraction from irrelevant regions
#
# Usage:
#   from ultralytics import YOLO
#   model = YOLO('yolo26-biformer.yaml')
#   model.train(data='tea.yaml', epochs=150, imgsz=640)

# Parameters
nc: 80  # number of classes (modify to your dataset, e.g., 1 for tea bud)
end2end: True  # whether to use end-to-end mode
reg_max: 1  # DFL bins
scales: # model compound scaling constants
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024]  # YOLO26-BiFormer-N
  s: [0.50, 0.50, 1024]  # YOLO26-BiFormer-S (recommended for comparison with yolo26s)
  m: [0.50, 1.00, 512]   # YOLO26-BiFormer-M
  l: [1.00, 1.00, 512]   # YOLO26-BiFormer-L
  x: [1.00, 1.50, 512]   # YOLO26-BiFormer-X

# YOLO26-BiFormer backbone with C2fBRA attention
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]             # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]            # 1-P2/4
  - [-1, 2, C3k2, [256, False, 0.25]]     # 2
  - [-1, 1, Conv, [256, 3, 2]]            # 3-P3/8
  - [-1, 2, C2fBRA, [512, False, 8, 4]]   # 4 <- C2fBRA (n_win=8, topk=4)
  - [-1, 1, Conv, [512, 3, 2]]            # 5-P4/16
  - [-1, 2, C2fBRA, [512, True, 8, 4]]    # 6 <- C2fBRA (n_win=8, topk=4)
  - [-1, 1, Conv, [1024, 3, 2]]           # 7-P5/32
  - [-1, 2, C2fBRA, [1024, True, 4, 4]]   # 8 <- C2fBRA (n_win=4, topk=4)
  - [-1, 1, SPPF, [1024, 5, 3, True]]     # 9
  - [-1, 2, C2PSA, [1024]]                # 10

# YOLO26-BiFormer head with P2 fusion + C2fBRA
head:
  # Top-down path
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]]             # cat backbone P4 (layer 6)
  - [-1, 2, C2fBRA, [512, True, 8, 4]]    # 13 <- C2fBRA

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]]             # cat backbone P3 (layer 4)
  - [-1, 2, C2fBRA, [256, True, 8, 4]]    # 16 (P3/8-small) <- C2fBRA

  # P2 feature fusion (improvement for small object detection)
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 2], 1, Concat, [1]]             # cat backbone P2 (layer 2)
  - [-1, 2, C3k2, [128, True]]            # 19 (P2/4-xsmall) <- new detection layer

  # Bottom-up path
  - [-1, 1, Conv, [128, 3, 2]]
  - [[-1, 16], 1, Concat, [1]]            # cat head P3
  - [-1, 2, C2fBRA, [256, True, 8, 4]]    # 22 (P3/8-small) <- C2fBRA

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 13], 1, Concat, [1]]            # cat head P4
  - [-1, 2, C2fBRA, [512, True, 8, 4]]    # 25 (P4/16-medium) <- C2fBRA

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]]            # cat head P5
  - [-1, 1, C3k2, [1024, True, 0.5, True]] # 28 (P5/32-large)

  # Detect head: P2, P3, P4, P5 (4-scale detection for small tea buds)
  - [[19, 22, 25, 28], 1, Detect, [nc]]   # Detect(P2, P3, P4, P5)
